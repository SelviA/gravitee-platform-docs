---
description: 20-25 minute intermediate tutorial
---

# Beginner: Security and Protocol Mediation

{% hint style="warning" %}
**Prerequisites**

1. To access the sample application, you must have a running Gravitee API Management enterprise trial as detailed in the [introduction to the tutorials](./#prerequisites).&#x20;
2. We highly recommend completing the [Quickstart guide](../quickstart-guide/) before completing this tutorial.
{% endhint %}

## Overview

This tutorial showcases Gravitee's event-native API management (APIM) capabilities that can manage, secure, and mediate between both asynchronous and synchronous protocols.

For those who are unfamiliar, event-native means that Gravitee is built on an event-driven architecture implemented with reactive programming to natively manage asynchronous, event-driven APIs. Gravitee fully supports synchronous (request/response) APIs management alongside asynchronous APIs in a centralized control plane, and can even mediate between synchronous and asynchronous protocols.

This tutorial shows how to properly configure these capabilities in APIM, and then demonstrates them inside a sample application.

### Access the sample app

Before beginning, you must ensure you have access to the sample application. The sample app can be accessed from any APIM [enterprise trial](../install-guides/free-trial.md) in the Console's sidebar with the **Open sample app** button:

{% hint style="warning" %}
Some ad blockers disable the **Open sample app** button. Please whitelist Gravitee products to avoid this.
{% endhint %}

<figure><img src="../../.gitbook/assets/Screenshot 2023-08-31 at 6.28.06 PM.png" alt=""><figcaption><p>Open the sample app from the top nav</p></figcaption></figure>

The sample application will not function properly if you do not access it from directly inside the Gravitee API Management enterprise trial.

## Sample app architecture

Each tutorial takes advantage of different aspects of the sample app. This section provides an overview of the relevant sample app functionality and architecture to help you get the most out of this tutorial. The next step of the tutorial will show you how to configure Gravitee API management (APIM) and how it augments the sample app architecture detailed here.&#x20;

{% hint style="info" %}
&#x20;For the curious, you can explore the application code in the [open-source, public repository](https://github.com/gravitee-io-labs/trial-sample-app).
{% endhint %}

This tutorial is built around the todo list page. The todo list page functions as a simple task manager built on the MERN stack. A MERN application is a type of web application that uses four main technologies:

* **MongoDB:** Stores and manages the application's data
* **Express.js:** Handles server-side routing and middleware
* **React.js:** Handles the frontend user interface and interactions
* **Node.js:** Handles the server-side logic and communication with the database

### Todo list: REST API

The REST API, and the `todos` resource the API manipulates and exposes, are the backbone of the todo list page. Consider the schema the `todos` resource:

<figure><img src="../../.gitbook/assets/image (6).png" alt=""><figcaption><p>Mindmap of the todos schema made in Gravitee API Designer</p></figcaption></figure>

The `todos` resource is created and modified through the endpoints shown in the image below, where `{id}` is a path parameter used to target a specific task in the collection. It should be noted that `userId` from the data schema and `id` in the API endpoints, are not related properties. The `userId` is tied to the user of the application while the `id` is a unique value autogenerated for every task created.

<figure><img src="../../.gitbook/assets/image (7).png" alt=""><figcaption><p>Backend API endpoints</p></figcaption></figure>

In the sample app, every available action directly related to task management is tied to one of these five endpoints.

{% hint style="info" %}
An endpoint consists of a URL _and an_ HTTP method. If you are unfamiliar with this terminology, check out our [API Fundamentals guide](https://documentation.gravitee.io/platform-overview/gravitee-essentials/api-fundamentals)!
{% endhint %}

For example, you can create a task by typing in the input box:

<figure><img src="../../.gitbook/assets/Screenshot 2023-08-10 at 4.32.13 PM.png" alt=""><figcaption><p>Task input box</p></figcaption></figure>

and pressing **Enter**:

<figure><img src="../../.gitbook/assets/Screenshot 2023-08-10 at 4.33.00 PM.png" alt=""><figcaption><p>Creating a task</p></figcaption></figure>

Pressing **Enter** triggers an action that sends a `POST` request to the `/todos` route on the Express.js server. The payload of the `POST` request contains a JSON object matching the structure of the `todos` schema, where the `text` property is set to "This is a task!". &#x20;

An API request occurs every time you create, complete, archive, or delete a task. Each API request follows a flow similar to the one detailed above.

### Todo list: Kafka

The todo list page is also integrated with a Kafka broker to help demonstrate APIM's capabilities with respect to protocol mediation and real-time, message-level data.&#x20;

Completing task management actions (i.e., creating, completing, archiving, and deleting tasks) produces data to a Kafka broker hosted on Confluent Cloud _without_ setting up or managing a Kafka client in the trial app.&#x20;

As we will demonstrate a bit later, the sample app is simply sending an HTTP `POST` request with a JSON payload to a Gateway API at the `/todo-actions` route. The Gravitee Gateway takes data sent to this endpoint and publishes it to the Kafka broker.&#x20;

Additionally, this same Gateway API also exposes a WebSocket endpoint at the `/todo-actions` route. The sample app has two WebSocket connections to the Gravitee Gateway through this endpoint. Any data published to the Kafka broker is consumed by these WebSocket connections _without_ setting up or managing a Kafka client in the sample app.

The Gravitee Gateway seamlessly mediates between HTTP, Kafka's binary protocol, and WebSockets. Let's dive into Gravitee's Console UI to learn a bit more about how this is set up.

## Gateway APIs

This tutorial uses two preconfigured Gateway APIs: **Trial App - Sync Use Cases** and **Trial App - Async Use Cases**:

<figure><img src="../../.gitbook/assets/image (13).png" alt=""><figcaption><p>Preconfigured Gateway APIs</p></figcaption></figure>

The synchronous Gateway API acts as a reverse proxy for [the REST API](real-time-data-and-protocol-mediation.md#todo-list-rest-api) that manages the basic functions of the trial app's task manager. This means that the Gateway API sits between API requests from the frontend client and the Express.js server on the backend. The image below shows the configuration of this backend service:

<figure><img src="../../.gitbook/assets/image (14).png" alt=""><figcaption><p>Sync API backend configuration</p></figcaption></figure>

However, the sample app is integrated with an additional **Backend service**: a Kafka broker. The Kafka broker cannot be included as an additional backend service in the same Gateway API because it requires a different type of Gateway API to handle message-level data. Consequently, a second Gateway API, **Trial App - Async Use Cases**, was created to manage the Kafka broker on the backend.&#x20;

APIM supports [two v4 API types](../../guides/create-apis/how-to/v4-api-creation-wizard.md#choose-your-backend-exposure-method): Proxy and Message. When creating your own Gateway APIs in the [v4 API creation wizard](../../guides/create-apis/how-to/v4-api-creation-wizard.md), you will encounter this choice between API types:

<figure><img src="../../.gitbook/assets/image (15).png" alt=""><figcaption><p>v4 API creation wizard</p></figcaption></figure>

The sync Gateway API integrated with the REST API is a Proxy API and the async Gateway API integrated with Kafka broker is a Message API. The **APIs** page in the APIM Console will show this information for each Gateway API under **Definition**:

<figure><img src="../../.gitbook/assets/Screenshot 2023-08-13 at 10.22.59 PM (1).png" alt=""><figcaption><p>Proxy and Message Gateway API</p></figcaption></figure>

Now let's see how to integrate the trial app with these APIs.

## Plans, Applications, and Subscriptions

API exposure in Gravitee APIM revolves around three pillars: plans, applications, and subscriptions. Once a Gateway API is started, deployed, and published (we've already done all three for you), it will be visible to API consumers, but cannot be consumed until a plan is published. Plans are an access layer around APIs that provide the API producer with a method to secure, monitor, and transparently communicate the details of access.

Plans can have several different authorization types. Besides the keyless authorization type, all other types of authorization (API Key, Push, JWT, and OAuth2.0) require the API consumer to register an application and subscribe to one of the published plans of that Gateway API.&#x20;

In addition to allowing an API consumer to register and agree to an API producer's plan, an application also enables an API publisher to closely monitor subscriptions and fine-tune access to its APIs. If one consumer turns out to be a bad actor engaging in malicious activity, applications provide API publishers with the granular control needed to revoke access for that one consumer instead of shutting the API down for all consumers.

{% hint style="info" %}
More advanced authorization methods like OAuth 2.0 require the client to provide information such as a client ID, which can be done when [registering an application](../../guides/api-exposure-plans-applications-and-subscriptions/plans-1.md).
{% endhint %}

### Create an APIM application

Next, we are going to create an application inside of APIM to allow us to subscribe to a plan with security for each Gateway API. This application essentially acts as an identifier for the sample app in your instance of APIM.&#x20;

However, we first want to enable a setting called [shared API keys](../../guides/api-exposure-plans-applications-and-subscriptions/plans.md#shared-api-key) which allows an application to use a single API key for multiple subscriptions.

#### Shared API key

For this feature to work properly, the shared API key setting must be enabled before creating an application.

To enable this feature, select **Settings** in the sidebar, then **Settings** again in the inner sidebar. Scroll to the **Console** section and check the **Allow to share API Key on an application** setting.

<figure><img src="../../.gitbook/assets/image (16).png" alt=""><figcaption><p>Enable shared API keys</p></figcaption></figure>

Finally, scroll to the bottom of the page and select **Save** to save your changes.

#### Create an application

Onto creating the actual application. Select the **Applications** tab in the sidebar of the APIM Console:

<figure><img src="../../.gitbook/assets/image (17).png" alt=""><figcaption><p>Applications page</p></figcaption></figure>

Then select + **Add application** on the top right of the page. Provide a name and description for your application. The domain of the application is the domain of the sample app: `https://gravitee-io-labs.github.io/trial-sample-app`. Add the domain, then select **Next**:

<figure><img src="../../.gitbook/assets/image (18).png" alt=""><figcaption><p>Application creation General screen</p></figcaption></figure>

On both the **Security** and **Subscriptions** screens, select **Skip.**

{% hint style="warning" %}
We are skipping the subscriptions screen because v4 API subscription requests can currently only be created from the Developer Portal. This method of creating subscriptions will be detailed in later tutorials.
{% endhint %}

Finally, review your application details on the Validation screen and select **Create The Application**:

<figure><img src="../../.gitbook/assets/image (19).png" alt=""><figcaption><p>Application creation Validation screen</p></figcaption></figure>

### Subscribe to the API Key Plans

We are now ready to subscribe our application to the API Key plans of both Gateway APIs.&#x20;

#### Proxy Gateway API

First, go to the **APIs** page and select the **Trial App - Sync Use Cases** API:

<figure><img src="../../.gitbook/assets/image (20).png" alt=""><figcaption><p>APIs page</p></figcaption></figure>

Inside the Gateway API, select **Plans** from the inner sidebar to see all of the plans associated with your API.

<figure><img src="../../.gitbook/assets/image (21).png" alt=""><figcaption><p>Plans page</p></figcaption></figure>

Policies can be assigned to [flows at the platform, API, or plan level](../../guides/policy-design/v4-api-policy-design-studio.md#design). For this Gateway API, a Quota policy is assigned to the **Basic Keyless Plan** and will be applied to all API requests that do not pass any form of authorization. To pass authorization, we need to receive a valid authorization token by subscribing to a plan that uses authorization: the **Premium API Key Plan**.

We are calling it "premium" because it does not have any API access restrictions like a Quota policy assigned to it, which allows API consumers subscribed to the plan to have unfettered access to the sample app's capabilities (i.e. API consumers subscribed to the premium plan can create an unlimited number of tasks).

You can verify this by taking a quick look at the **Policy Studio** page. The **Limit Creation of Tasks** flow is assigned to the **Basic Keyless Plan**:

<figure><img src="../../.gitbook/assets/image (22).png" alt=""><figcaption><p>Sync API Policy Studio</p></figcaption></figure>

To continue creating a subscription, return to the **Plans** page and select the **Subscriptions** tab at the top. As you can see below, there are currently no subscriptions to this Gateway API.

{% hint style="info" %}
Consuming an API through a Keyless plan does **not** require a subscription.
{% endhint %}

<figure><img src="../../.gitbook/assets/image (23).png" alt=""><figcaption><p>Sync API subscriptions</p></figcaption></figure>

Click **+ Create a subscription** on the top right. In the modal, search for and select your application, select the **Premium API Key Plan**, and click **Create**:

<figure><img src="../../.gitbook/assets/image (24).png" alt=""><figcaption><p>Sync API - Create a subscription</p></figcaption></figure>

You may need to refresh the page, but then you should see your new subscription immediately.&#x20;

{% hint style="info" %}
In this tutorial, you are acting as both the API Publisher and API Consumer, so the Premium API Key Plan is set to [auto-validate all subscription requests](../../guides/api-exposure-plans-applications-and-subscriptions/plans.md#general). Future tutorials will walk you through how to create a plan without auto-validation and how to manage and approve subscription requests.
{% endhint %}

<figure><img src="../../.gitbook/assets/image (25).png" alt=""><figcaption><p>Trial App's first subscription</p></figcaption></figure>

We must now create a second subscription to the Message Gateway API.

#### Message Gateway API

Repeat the process you just completed for the Proxy Gateway API, with one change to the last step:

1. Select **APIs** in the sidebar
2. Select the **Trial App - Async Use Cases** API
3. Select **Plans** in the inner sidebar, then click on the **Subscriptions** tab
4. Click **+ Create a Subscription**
5. Search for and select your application, select the **Premium API Key Plan**, select **Shared API Key**, and click **Create**

<figure><img src="../../.gitbook/assets/image (26).png" alt=""><figcaption><p>Create a subscription with a shared API key</p></figcaption></figure>

Your application is now subscribed to an API Key Plan for each Gateway API using the same autogenerated API key.&#x20;

{% hint style="danger" %}
A shared API key was used to simplify several aspects of this tutorial. Before using a shared API key in production applications, you should be [aware of the implications](../../guides/api-exposure-plans-applications-and-subscriptions/plans.md#shared-api-key).
{% endhint %}

## Configure the Sample App

With the subscriptions set up, you need to provide the sample app the API key to use in its requests to the Gravitee Gateway.&#x20;

First, open the subscription you just created and scroll to the bottom of the page:

<figure><img src="../../.gitbook/assets/image (27).png" alt=""><figcaption><p>Access subscription's API key</p></figcaption></figure>

Copy the API key to your clipboard and open the trial app. Select **Configuration** in the sidebar:

<figure><img src="../../.gitbook/assets/Screenshot 2023-09-04 at 11.09.34 PM.png" alt=""><figcaption><p>Trial app configuration</p></figcaption></figure>

Under the **Authorization** header, select **API Key** and paste the API key inside the input box.&#x20;

Next, select **On** under the **Analytics** header. Finally, select **Save Changes** on the top right.

<figure><img src="../../.gitbook/assets/Screenshot 2023-09-04 at 11.10.27 PM.png" alt=""><figcaption><p>Save updated configuration</p></figcaption></figure>

### Test API Key Plan subscriptions

With the modifications you just made, each of the sample app's requests to the `/todos` route will include an `X-Gravitee-Api-Key` header that contains your API key. The Gravitee Gateway will detect the `X-Gravitee-Api-Key` header and [automatically select the Premium API Key Plan](../../guides/api-exposure-plans-applications-and-subscriptions/plans.md#plan-selection).

To test this, return to the **Todo List** in the trial app. The new subscription to the API Key Plan allows you to circumvent the Quota policy tied to the keyless plan and create an unlimited number of tasks:

<figure><img src="../../.gitbook/assets/Screenshot 2023-08-13 at 11.25.28 PM.png" alt=""><figcaption><p>Unrestricted API access</p></figcaption></figure>

With both the application and Gravitee Gateway functioning as expected, we are ready to demonstrate APIM's event-native functionality.

## Event-native API Management

Let's experiment with protocol mediation using the analytic graphs. In the sample app, return to the **Configuration** page and select the **On** toggle underneath the **Analytic Graphs** header:

<figure><img src="../../.gitbook/assets/Screenshot 2023-09-04 at 11.10.56 PM.png" alt=""><figcaption><p>Turn on analytic graphs</p></figcaption></figure>

Make sure you save your changes then return to the **Todo List** page. Depending on what actions you completed on the Todo List page, the graphs should already contain some data:

{% hint style="warning" %}
If you see the message "One or more WebSocket connections have failed. Please refresh the page." on the analytics page, refresh the trial app before continuing.
{% endhint %}

<figure><img src="../../.gitbook/assets/Screenshot 2023-08-13 at 11.41.03 PM.png" alt=""><figcaption><p>Analytic graphs turned on</p></figcaption></figure>

Let's start with a clean slate. Select the **Clear Graphs** button in the top right. Begin creating, completing, deleting, and archiving tasks to see the graphs respond to your actions. As you might have guessed from the graph titles, one graph responds immediately while the other has a several-second delay. This is all enabled via our second Gateway API, **Trial App - Async Use Cases**.

{% hint style="info" %}
The **Clear Graphs** button does not actually delete any data from the Kafka broker. It simply resets the graphs while the WebSocket connections remain open for new data.
{% endhint %}

Each action you complete sends a `POST` request to the Gravitee Gateway at the `/todo-actions` route. The Gateway receives the request payload and publishes a message with the payload to a specific topic on the Kafka broker. This has been preconfigured in the Message Gateway API's backend services. Mediating between the HTTP protocol and Kafka's binary TCP protocol is handled automatically by the Gravitee Gateway. Gravitee's event-native capabilities allow you to act as a Kafka Producer without any complex configuration or custom code.

Additionally, each graph has its own WebSocket connection to the Gravitee Gateway at the `/todo-actions` route.  Every message published to a specific topic on the Kafka broker is consumed by the Gateway and pushed to the WebSocket connections. This has been preconfigured in the Message Gateway API's backend services. Mediating between Kafka's binary TCP protocol and the WebSocket protocol is handled automatically by the Gravitee Gateway. Gravitee's event-native capabilities allow you to act as a Kafka consumer without any complex configuration or custom code.

{% hint style="info" %}
Although disabled for the **Trial App - Async Use Cases Gateway API**, you can configure a Gateway API to allow clients to produce messages from a WebSocket connection.
{% endhint %}

Now, if both graphs have a WebSocket connection at the same route, why is only one graph receiving real-time data? Let's return to the APIM Console to investigate.

### Message-level policies

In the APIM Console, navigate to the **APIs** page, then select **Trial App - Async Use Cases:**

<figure><img src="../../.gitbook/assets/image (31).png" alt=""><figcaption><p>Message Gateway API</p></figcaption></figure>

Next, head over to the **Policy Studio**. There are two plans here: a **Basic Keyless Plan** and a **Premium API Key Plan**:

<figure><img src="../../.gitbook/assets/image (32).png" alt=""><figcaption><p>Async Gateway API Policy Studio</p></figcaption></figure>

Earlier we subscribed to the Premium API Key Plan in the APIM Console, but how does the Gravitee Gateway know which API requests belong to which plan? As explained in more detail [here](../../guides/api-exposure-plans-applications-and-subscriptions/plans.md#plan-selection), Gravitee looks for a header or query parameter passing an authorization token. If another plan has detected a security token, valid or invalid, all flows assigned to the Keyless plan will be ignored.&#x20;

In the case of the trial app, one WebSocket connection passes an API key (real-time graph) and the other WebSocket connection establishes a connection without any authorization (delayed graph). Therefore, the delayed graph has the **Delay Real-time Data** flow applied to its connection. Let's take a closer look at this flow.

Select the **Delay Real-time Data** flow, then under **Flow Details**, select **Event Messages** to see policies applied at the message level.

{% hint style="info" %}
As detailed [here](../../guides/policy-design/v4-api-policy-design-studio.md#design), Message APIs can have policies that are applied during the initial connection in addition to policies that are applied on each individual message.
{% endhint %}

<figure><img src="../../.gitbook/assets/image (33).png" alt=""><figcaption><p>Latency policy applied at the message level</p></figcaption></figure>

This shows that a Latency policy is applied to all event messages on the subscribe phase. To see more details, select the three-dot menu on the Latency policy, then select **Edit**.

<figure><img src="../../.gitbook/assets/image (34).png" alt=""><figcaption><p>Edit latency policy</p></figcaption></figure>

A delay of four seconds is added to every message on the subscribe phase:

<figure><img src="../../.gitbook/assets/image (35).png" alt=""><figcaption><p>Latency policy configuration</p></figcaption></figure>

Each action completed on the **Todo List** page results in a new message being produced which adds an additional four-second delay. This explains why the delayed graph is updated after the real-time graph. The delay creates a backlog because each action is consumed by the WebSocket in the order the message was produced.&#x20;

This backlog is why the delayed graph can continue receiving data after clearing the graphs. For example, inside the sample app, rapidly select the checkbox for one task about 10 times then select the **Clear Graphs** button and wait. Because the real-time graph consumed all the messages from the Kafka broker in real time, it has no new data to consume. However, the delayed graph acts as a separate Kafka consumer and is essentially drip-fed the data in the backlog.

<figure><img src="../../.gitbook/assets/Screenshot 2023-08-13 at 11.55.07 PM.png" alt=""><figcaption><p>Delayed graph backlog</p></figcaption></figure>

You may be asking why you would ever want to add latency to the consumption of your data. Besides testing to ensure robust handling of APIs on the client side, latency can be used for monetization use cases. The above flow allows you to restrict access to your valuable, real-time data to customers who pay for a premium plan while still giving prospects access to a restricted (in this case, restricted with latency) data stream.

{% hint style="success" %}
Congratulations! You've just experienced the power of Gravitee's event-native API management.&#x20;

You can now move on to another advanced tutorial or even modify this policy to see the impact on the sample app. Just don't forget to redeploy the API after saving!
{% endhint %}

## Appendix: Kafka consumer groups

{% hint style="warning" %}
This section is only recommended for users already familiar with Kafka.&#x20;
{% endhint %}

The data shown in the analytics graphs is data that has been consumed from a Kafka broker. This can result in some confusing behavior if you're unfamiliar with how Gravitee APIM handles client identifiers and consumer groups.

As detailed [here](broken-reference), APIM follows specific rules for determining a consumer's client identifier which Kafka uses to compute the consumer group. In summary:

> By default, every subscription creates a new client identifier, and therefore, a new consumer group. If there is no subscription required (i.e., a Keyless Plan), then the client's IP address is used to create or find the client identifier.

The sample app provides a concrete example. Each graph has a WebSocket connection tied to a different plan. Specifically, there is a subscription to the API Key Plan and a connection to a Keyless Plan. This results in two consumer groups where each graph will receive all messages published to the Kafka broker.&#x20;

These two consumer groups will persist for the life of the subscriptions. However, in some cases, this may not be ideal. Let's take the sample app for example:

1. Duplicating the sample app in a new tab results in an additional consumer joining each consumer group. And because we set up the Kafka topic with one partition, the first consumer from each group to connect will receive all the messages from that partition until it disconnects.
2. Refreshing the page results in losing your "analytics history" from the perspective of the application. This is because refreshing the page creates a new consumer that is still part of the same consumer group.

{% hint style="info" %}
To distribute the load between multiple consumers in a single consumer group, you must create additional partitions in your Kafka topic. Per consumer group, Kafka only allows for a single consumer per partition.
{% endhint %}

You can verify these limitations yourself by duplicating the sample app in your browser and completing actions. The graphs in the original sample app tab will receive all the data.

You may prefer each instance of the sample app to create two new consumer groups. Thankfully, Gravitee enables this:

> To manually create a new consumer group, pass the `X-Gravitee-Client-Identifier` header or query parameter with a unique value.

With this, Gravitee provides an easy way to create a new consumer group without creating a new subscription.&#x20;

The sample app can take advantage of this functionality. Head back to the Configuration page and select the **On with history** toggle under **Analytics Graphs**.

<figure><img src="../../.gitbook/assets/Screenshot 2023-09-04 at 11.36.09 PM.png" alt=""><figcaption><p>Enable history in the analytics graphs</p></figcaption></figure>

This setting essentially modifies the sample app to generate and pass a universally unique identifier (UUID) as the `X-Gravitee-Client-Identifier` query parameter when establishing each WebSocket connection. A new UUID is generated every time you refresh the page.

From here, you should be able to duplicate the sample app as many times as you desire. Each instance of the application will receive all the data generated by any instance of the application. This is because each instance of the sample app is still publishing data to the same Kafka topic, but now has consumers in totally separate consumer groups.

Additionally, since we configured the Kafka endpoint with the [earliest offset](https://docs.confluent.io/platform/current/clients/consumer.html#offset-management), each new instance will receive all the messages ever published to the Kafka broker, even if that sample app instance did not exist when the message was produced. This maintains your analytics history but may not be ideal for the delayed graph as the backlog of data will quickly become massive. If preferred, you can easily change to the latest offset in the Messages API's **Backend services** configuration.&#x20;

Feel free to experiment with any of the settings and policies to test the impact on the trial app.

{% hint style="success" %}
Congrats! You've completed the extended edition of this tutorial!
{% endhint %}
